#!/usr/bin/env bash

# Shellscript support function file for Kubernetes Make targets

function k8sChartVersion() {
	if [ -z "$1" ] ; then
		echo "k8sChartVersion: Missing K8S_CHART"
        exit 1
	fi
    K8S_CHART="$1"

    if [[ -z "${K8S_HELM_REPOSITORY}" ]]; then
		echo "k8sChartVersion: Missing K8S_HELM_REPOSITORY"
        exit 1
    fi
    (helm repo list | grep "${K8S_HELM_REPOSITORY}" >/dev/null) || (echo "k8sChartVersion: repo ${K8S_HELM_REPOSITORY} is not set"; exit 1;)
    K8S_REPO=$(helm repo list | grep "${K8S_HELM_REPOSITORY}" | awk '{print $1}')
    helm repo update ${K8S_REPO} >/dev/null 2>&1
    k8s_ver_check=$?
    if ! [[ $k8s_ver_check -eq 0 ]]; then
		echo "k8sChartVersion: could not update K8S_HELM_REPOSITORY ${K8S_HELM_REPOSITORY}(${K8S_REPO})"
        exit 1
    fi
    which jq >/dev/null 2>&1 || (echo "jq not installed - see https://stedolan.github.io/jq/"; exit 1;)
    K8S_CHART_VERSION=`helm search repo -o json ${K8S_CHART}  | jq -r '.[].version' | head -1`;
    if [[ -z "${K8S_CHART_VERSION}" ]]; then
		echo "k8sChartVersion: version for ${K8S_CHART} in ${K8S_HELM_REPOSITORY} could not be found"
        exit 1
    fi
    echo ${K8S_CHART_VERSION}
}

function k8sWait() {
	if [ -z "$1" ] ; then
		echo "k8sWait: Missing KUBE_NAMESPACE"
        exit 1
	fi
    KUBE_NAMESPACE="$1"
	K8S_NAMESPACE_TANGO_OPERATOR_DEPLOYED="$2"
	K8S_WAIT_FAIL_IF_JOB_MISSING="$3"

	if [ "$K8S_NAMESPACE_TANGO_OPERATOR_DEPLOYED" = "true" ]; then
		echo "k8sWait: waiting for DatabaseDS(s) and DeviceServer(s) to be ready in '${KUBE_NAMESPACE}'"
		date
		kubectl -n ${KUBE_NAMESPACE} get databaseds.tango.tango-controls.org,deviceservers.tango.tango-controls.org
		DATABASE_DS=$(kubectl get databaseds.tango.tango-controls.org -l app=${KUBE_APP} -n ${KUBE_NAMESPACE} -o jsonpath='{.items[*].metadata.name}')
		DEVICE_SERVERS=$(kubectl get deviceservers.tango.tango-controls.org -l app=${KUBE_APP} -n ${KUBE_NAMESPACE} -o jsonpath='{.items[*].metadata.name}')
		echo "k8sWait: DatabaseDS(s) found: $DATABASE_DS"
		echo "k8sWait: DeviceServer(s) found: $DEVICE_SERVERS"

		if [[ -z "${DATABASE_DS}" ]]; then
			echo "k8sWait: no DatabaseDS(s) found to wait for"
		else
			time kubectl wait databaseds.tango.tango-controls.org --for=jsonpath='{.status.state}'=Running --timeout=${K8S_TIMEOUT} $DATABASE_DS -n ${KUBE_NAMESPACE}
			WAIT_RESULT=$?
			if [[ $WAIT_RESULT == 0 ]]; then
				echo "k8sWait: DatabaseDS(s) running - $DATABASE_DS"
			else
				echo "k8sWait: DatabaseDS(s) not running! "
				if [ "$VERBOSE_WAIT" = "true" ]; then
					kubectl get events -n ${KUBE_NAMESPACE} --sort-by=.metadata.creationTimestamp | tac
					k8sPodLogs ${KUBE_NAMESPACE} ${KUBE_APP}
				fi
				exit $WAIT_RESULT
			fi
		fi

		if [[ -z "${DEVICE_SERVERS}" ]]; then
			echo "k8sWait: no DeviceServer(s) found to wait for"
		else
			time kubectl wait deviceservers.tango.tango-controls.org --for=jsonpath='{.status.state}'=Running --timeout=${K8S_TIMEOUT} $DEVICE_SERVERS -n ${KUBE_NAMESPACE}
			WAIT_RESULT=$?
			if [[ $WAIT_RESULT == 0 ]]; then
				echo "k8sWait: DeviceServer(s) running - $DEVICE_SERVERS"
			else
				echo "k8sWait: DeviceServer(s) not running! "
				if [ "$VERBOSE_WAIT" = "true" ]; then
					kubectl get events -n ${KUBE_NAMESPACE} --sort-by=.metadata.creationTimestamp | tac
					k8sPodLogs ${KUBE_NAMESPACE} ${KUBE_APP}
				fi
				exit $WAIT_RESULT
			fi
		fi
	fi

	echo "k8sWait: waiting for jobs to be ready in '${KUBE_NAMESPACE}'"
	K8S_WAIT_JOBS=$(kubectl get job --output=jsonpath={.items..metadata.name} -n ${KUBE_NAMESPACE})
	echo "k8sWait: Jobs found: $K8S_WAIT_JOBS"
	if [[ -z "${K8S_WAIT_JOBS}" ]]; then
		echo "k8sWait: no Jobs found to wait for using: kubectl get job --output=jsonpath={.items..metadata.name} -n ${KUBE_NAMESPACE}"
	else
		# Looping for every job because they might get deleted in the meantime
		for JOB in $K8S_WAIT_JOBS; do
			FAILED="false"
			kubectl get job --output=jsonpath={.items..metadata.name} -n ${KUBE_NAMESPACE} $JOB
			WAIT_RESULT=$?
			if [[ $WAIT_RESULT != 0 ]]; then
				if [ "$K8S_WAIT_FAIL_IF_JOB_MISSING" != "true" ]; then
					WAIT_RESULT=0
				fi
			else
				time kubectl wait job --for=condition=complete --timeout=${K8S_TIMEOUT} $JOB -n ${KUBE_NAMESPACE}
				WAIT_RESULT=$?
			fi

			if [[ $WAIT_RESULT != 0 ]]; then
				echo "k8sWait: jobs FAILED! "
				if [ "$VERBOSE_WAIT" = "true" ]; then
					kubectl get events -n ${KUBE_NAMESPACE} --sort-by=.metadata.creationTimestamp | tac
					kubectl -n ${KUBE_NAMESPACE} get job
					k8sPodLogs ${KUBE_NAMESPACE} ${KUBE_APP}
				fi
				exit $WAIT_RESULT
			fi
		done

		echo "k8sWait: Jobs complete - $K8S_WAIT_JOBS"
	fi

	date
	k8s_wait_pods=$(kubectl get pod -l app=${KUBE_APP} --output=jsonpath={.items..metadata.name} -n ${KUBE_NAMESPACE})
	echo "k8sWait: Pods found: $k8s_wait_pods"
	if [[ -z "${k8s_wait_pods}" ]]; then
		echo "k8sWait: no Pods found to wait for using: kubectl get pod -l app=${KUBE_APP} --output=jsonpath={.items..metadata.name} -n ${KUBE_NAMESPACE}"
		exit 0
	fi

	echo "k8sWait: going to - kubectl -n ${KUBE_NAMESPACE} wait --for=condition=ready --timeout=${K8S_TIMEOUT} pods ${k8s_wait_pods}"
	time kubectl -n ${KUBE_NAMESPACE} wait --for=condition=ready --timeout=${K8S_TIMEOUT} pods ${k8s_wait_pods}
	wait_result=$?
	if [[ $wait_result == 0 ]]; then
		echo "k8sWait: all Pods ready"
		kubectl -n ${KUBE_NAMESPACE} get pods -o jsonpath='{range .items[*]}Pod: {@.metadata.name}{"\n"}Containers:{"\n"}{range @.spec.containers[*]}{@.name} => {@.image}{"\n"}{end}{"\n"}{end}'
	else
		echo "k8sWait: Pods FAILED!"
		if [ "$VERBOSE_WAIT" = "true" ]; then
			kubectl get events -n ${KUBE_NAMESPACE} --sort-by=.metadata.creationTimestamp | tac
			kubectl -n ${KUBE_NAMESPACE} get pods
			k8sPodLogs ${KUBE_NAMESPACE} ${KUBE_APP}
		fi
		exit $wait_result
	fi;
	date
}

function k8sDescribe() {
	if [ -z "$1" ] ; then
		echo "k8sDescribe: Missing KUBE_NAMESPACE"
        exit 1
	fi
    KUBE_NAMESPACE="$1"
	if [ -z "$2" ] ; then
		echo "k8sDescribe: Missing KUBE_APP"
        exit 1
	fi
    KUBE_APP="$2"

	for i in `kubectl -n ${KUBE_NAMESPACE} get pods -l app=${KUBE_APP} -o=name`
	do
        echo "---------------------------------------------------"
        echo "k8sDescribe: describe for ${i}"
        echo kubectl -n ${KUBE_NAMESPACE} describe ${i}
        echo "---------------------------------------------------"
        kubectl -n ${KUBE_NAMESPACE} describe ${i}
        echo "---------------------------------------------------"
        echo ""; echo ""; echo ""
	done
}

function k8sPodLogs() {
	if [ -z "$1" ] ; then
		echo "k8sPodLogs: Missing KUBE_NAMESPACE"
        exit 1
	fi
    KUBE_NAMESPACE="$1"
	if [ -z "$2" ] ; then
		echo "k8sPodLogs: Missing KUBE_APP"
        exit 1
	fi
    KUBE_APP="$2"

	for i in `kubectl -n ${KUBE_NAMESPACE} get pods -l app=${KUBE_APP} -o=name`
	do \
        echo "---------------------------------------------------"
        echo "Logs for ${i}"
        echo kubectl -n ${KUBE_NAMESPACE} logs ${i}
        echo kubectl -n ${KUBE_NAMESPACE} get ${i} -o jsonpath="{.spec.initContainers[*].name}"
        echo "---------------------------------------------------"
        for j in `kubectl -n ${KUBE_NAMESPACE} get ${i} -o jsonpath="{.spec.initContainers[*].name}"`; do \
            RES=`kubectl -n ${KUBE_NAMESPACE} logs ${i} -c ${j} 2>/dev/null`
            echo "initContainer: ${j}"; echo "${RES}"
            echo "---------------------------------------------------";\
        done
        echo "Main Pod logs for ${i}"
        echo "---------------------------------------------------"
        for j in `kubectl -n ${KUBE_NAMESPACE} get ${i} -o jsonpath="{.spec.containers[*].name}"`; do \
            RES=`kubectl -n ${KUBE_NAMESPACE} logs ${i} -c ${j} 2>/dev/null`
            echo "Container: ${j}"; echo "${RES}"
            echo "---------------------------------------------------";\
        done
        echo "---------------------------------------------------"
        echo ""; echo ""; echo ""
	done
}

function getNamespaceLinks(){
	JOB_START_TIME_KIBANA="${CI_JOB_STARTED_AT}"
	JOB_START_TIME_GRAFANA=$(($(date -d "${CI_JOB_STARTED_AT}" +%s) * 1000))
	if [[ ${KUBE_NAMESPACE} = ci* ]] ; then
		JOB_END_TIME_KIBANA=$(date -d "${CI_JOB_STARTED_AT} + 2 hours" +"%Y-%m-%dT%H:%M:%SZ")
		JOB_END_TIME_GRAFANA=$((${JOB_START_TIME_GRAFANA} + 2 * 3600 * 1000))
	else
		JOB_END_TIME_KIBANA=$(date -d "${CI_JOB_STARTED_AT} + 8 hours" +"%Y-%m-%dT%H:%M:%SZ")
		JOB_END_TIME_GRAFANA=$((${JOB_START_TIME_GRAFANA} + 8 * 3600 * 1000))
	fi

	DATACENTRE_ENVIRONMENT_FILTER="('\$state':(store:appState),meta:(alias:!n,disabled:!f,index:${CLUSTER_KIBANA_VIEW_ID},negate:!f,params:!(('\$state':(store:appState),meta:(alias:!n,disabled:!f,index:${CLUSTER_KIBANA_VIEW_ID},negate:!f,params:!((meta:(alias:!n,disabled:!f,field:ska.datacentre,index:${CLUSTER_KIBANA_VIEW_ID},key:ska.datacentre,negate:!f,params:(query:${CLUSTER_DATACENTRE}),type:phrase),query:(match_phrase:(ska.datacentre:${CLUSTER_DATACENTRE}))),(meta:(alias:!n,disabled:!f,field:ska.environment,index:${CLUSTER_KIBANA_VIEW_ID},key:ska.environment,negate:!f,params:(query:${CLUSTER_ENVIRONMENT}),type:phrase),query:(match_phrase:(ska.environment:${CLUSTER_ENVIRONMENT})))),relation:AND,type:combined)),(meta:(alias:!n,disabled:!f,field:ska.prometheus_datacentre,index:${CLUSTER_KIBANA_VIEW_ID},key:ska.prometheus_datacentre,negate:!f,params:(query:${CLUSTER_MONITOR}),type:phrase),query:(match_phrase:(ska.prometheus_datacentre:${CLUSTER_MONITOR})))),relation:OR,type:combined),query:()))"
	NAMESPACE_DS="${CLUSTER_HEADLAMP_BASE_URL}/c/${CLUSTER_HEADLAMP_CLUSTER_ID}/namespaces/${KUBE_NAMESPACE}"
	DEVICESERVER_DS="${CLUSTER_HEADLAMP_BASE_URL}/c/${CLUSTER_HEADLAMP_CLUSTER_ID}/customresources/deviceservers.tango.tango-controls.org"
	DATABASE_DS="${CLUSTER_HEADLAMP_BASE_URL}/c/${CLUSTER_HEADLAMP_CLUSTER_ID}/customresources/databaseds.tango.tango-controls.org"
	JOB_LOGS="${CLUSTER_KIBANA_BASE_URL}/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:60000),time:(from:'${JOB_START_TIME_KIBANA}',to:'${JOB_END_TIME_KIBANA}'))&_a=(columns:!(message),filters:!(('\$state':(store:appState),meta:(alias:!n,disabled:!f,field:kubernetes.labels.cicd_skao_int%2FjobId,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.labels.cicd_skao_int%2FjobId,negate:!f,params:(query:'${CI_JOB_ID}'),type:phrase),query:(match_phrase:(kubernetes.labels.cicd_skao_int%2FjobId:'${CI_JOB_ID}')))),grid:(columns:('@timestamp':(width:128))),index:${CLUSTER_KIBANA_VIEW_ID},interval:auto,query:(language:kuery,query:'kubernetes.pod.name:%20runner-*-concurrent-*%20'),rowsPerPage:500,sort:!(!('@timestamp',asc)))"
	TESTPOD_LOGS="${CLUSTER_KIBANA_BASE_URL}/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:60000),time:(from:'${JOB_START_TIME_KIBANA}',to:'${JOB_END_TIME_KIBANA}'))&_a=(columns:!(message),filters:!(('\$state':(store:appState),meta:(alias:!n,disabled:!f,field:kubernetes.pod.name,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.pod.name,negate:!f,params:(query:${K8S_TEST_RUNNER}),type:phrase),query:(match_phrase:(kubernetes.pod.name:${K8S_TEST_RUNNER})))),grid:(columns:('@timestamp':(width:128))),index:${CLUSTER_KIBANA_VIEW_ID},interval:auto,query:(language:kuery,query:''),rowsPerPage:500,sort:!(!('@timestamp',asc)))"
	NAMESPACE_LOGS="${CLUSTER_KIBANA_BASE_URL}/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:60000),time:(from:'${JOB_START_TIME_KIBANA}',to:'${JOB_END_TIME_KIBANA}'))&_a=(columns:!(kubernetes.pod.name,message),filters:!(('\$state':(store:appState),meta:(alias:!n,disabled:!f,field:kubernetes.namespace,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.namespace,negate:!f,params:(query:${KUBE_NAMESPACE}),type:phrase),query:(match_phrase:(kubernetes.namespace:${KUBE_NAMESPACE}))),('\$state':(store:appState),meta:(alias:!n,disabled:!f,field:kubernetes.pod.name,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.pod.name,negate:!t,params:(query:${K8S_TEST_RUNNER}),type:phrase),query:(match_phrase:(kubernetes.pod.name:${K8S_TEST_RUNNER}))),${DATACENTRE_ENVIRONMENT_FILTER},grid:(columns:('@timestamp':(width:128),kubernetes.pod.name:(width:256))),index:${CLUSTER_KIBANA_VIEW_ID},interval:auto,query:(language:kuery,query:''),rowsPerPage:500,sort:!(!('@timestamp',asc)))"
	DEVICECONF_LOGS="${CLUSTER_KIBANA_BASE_URL}/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:60000),time:(from:'${JOB_START_TIME_KIBANA}',to:'${JOB_END_TIME_KIBANA}'))&_a=(columns:!(kubernetes.job.name,message),filters:!(('\$state':(store:appState),meta:(alias:!n,disabled:!f,index:${CLUSTER_KIBANA_VIEW_ID},negate:!f,params:!(('\$state':(store:appState),meta:(alias:!n,disabled:!f,index:${CLUSTER_KIBANA_VIEW_ID},negate:!f,params:!((meta:(alias:!n,disabled:!f,field:kubernetes.labels.cicd_skao_int%2FjobId,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.labels.cicd_skao_int%2FjobId,negate:!f,params:(query:'${CI_JOB_ID}'),type:phrase),query:(match_phrase:(kubernetes.labels.cicd_skao_int%2FjobId:'${CI_JOB_ID}'))),(meta:(alias:!n,disabled:!f,field:kubernetes.job.name,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.job.name,negate:!f,type:exists,value:exists),query:(exists:(field:kubernetes.job.name)))),relation:AND,type:combined)),('\$state':(store:appState),meta:(alias:!n,disabled:!f,index:${CLUSTER_KIBANA_VIEW_ID},negate:!f,params:!((meta:(alias:!n,disabled:!f,field:kubernetes.namespace,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.namespace,negate:!f,params:(query:ska-tango-operator),type:phrase),query:(match_phrase:(kubernetes.namespace:ska-tango-operator))),(meta:(alias:!n,disabled:!f,field:message,index:${CLUSTER_KIBANA_VIEW_ID},key:message,negate:!f,params:(query:${KUBE_NAMESPACE}),type:phrase),query:(match_phrase:(message:${KUBE_NAMESPACE})))),relation:AND,type:combined))),relation:OR,type:combined),query:())),grid:(columns:('@timestamp':(width:128),kubernetes.job.name:(width:256))),index:${CLUSTER_KIBANA_VIEW_ID},interval:auto,query:(language:kuery,query:''),rowsPerPage:500,sort:!(!('@timestamp',asc)))"
	DEVICESERVER_LOGS="${CLUSTER_KIBANA_BASE_URL}/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:60000),time:(from:'${JOB_START_TIME_KIBANA}',to:'${JOB_END_TIME_KIBANA}'))&_a=(columns:!(kubernetes.pod.name,message),filters:!(('\$state':(store:appState),meta:(alias:!n,disabled:!f,field:kubernetes.namespace,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.namespace,negate:!f,params:(query:${KUBE_NAMESPACE}),type:phrase),query:(match_phrase:(kubernetes.namespace:${KUBE_NAMESPACE}))),('\$state':(store:appState),meta:(alias:!n,disabled:!f,field:kubernetes.job.name,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.job.name,negate:!t,type:exists,value:exists),query:(exists:(field:kubernetes.job.name))),${DATACENTRE_ENVIRONMENT_FILTER},grid:(columns:('@timestamp':(width:128),kubernetes.pod.name:(width:256))),index:${CLUSTER_KIBANA_VIEW_ID},interval:auto,query:(language:kuery,query:'(not%20kubernetes.statefulset.name:%20*databaseds*)%20and%20(not%20kubernetes.statefulset.name:%20*tangodb*)'),rowsPerPage:500,sort:!(!('@timestamp',asc)))"
	DATABASEDS_LOGS="${CLUSTER_KIBANA_BASE_URL}/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:60000),time:(from:'${JOB_START_TIME_KIBANA}',to:'${JOB_END_TIME_KIBANA}'))&_a=(columns:!(kubernetes.pod.name,message),filters:!(('\$state':(store:appState),meta:(alias:!n,disabled:!f,field:kubernetes.namespace,index:${CLUSTER_KIBANA_VIEW_ID},key:kubernetes.namespace,negate:!f,params:(query:${KUBE_NAMESPACE}),type:phrase),query:(match_phrase:(kubernetes.namespace:${KUBE_NAMESPACE}))),${DATACENTRE_ENVIRONMENT_FILTER},grid:(columns:('@timestamp':(width:128),kubernetes.pod.name:(width:256))),index:${CLUSTER_KIBANA_VIEW_ID},interval:auto,query:(language:kuery,query:'kubernetes.statefulset.name:%20*databaseds*%20or%20kubernetes.statefulset.name:%20*tangodb*'),rowsPerPage:500,sort:!(!('@timestamp',asc)))"
	NAMESPACE_METRICS="${CLUSTER_MONITORING_BASE_URL}/d/dad0e09f-32f5-4181-b273-c7a1017221ff/kubernetes-resource-monitoring-dashboard?orgId=1&var-datasource=default&var-cluster=${CLUSTER_MONITOR}&var-namespace=${KUBE_NAMESPACE}&from=${JOB_START_TIME_GRAFANA}&to=${JOB_END_TIME_GRAFANA}"
	DEVICESERVER_METRICS="${CLUSTER_MONITORING_BASE_URL}/d/e0tiv654z/kubernetes-compute-resources-deviceserver?orgId=1&var-datasource=default&var-cluster=${CLUSTER_MONITOR}&var-namespace=${KUBE_NAMESPACE}&var-pod=&from=${JOB_START_TIME_GRAFANA}&to=${JOB_END_TIME_GRAFANA}"
	WORKLOAD_METRICS="${CLUSTER_MONITORING_BASE_URL}/d/a87fb0d919ec0ea5f6543124e16c42a5/kubernetes-compute-resources-namespace-workloads?orgId=1&refresh=10s&var-datasource=default&var-cluster=${CLUSTER_MONITOR}&var-namespace=${KUBE_NAMESPACE}&var-type=All&from=${JOB_START_TIME_GRAFANA}&to=${JOB_END_TIME_GRAFANA}"
	POD_METRICS="${CLUSTER_MONITORING_BASE_URL}/d/85a562078cdf77779eaa1add43ccec1e/kubernetes-compute-resources-namespace-pods?orgId=1&refresh=10s&var-datasource=default&var-cluster=${CLUSTER_MONITOR}&var-namespace=${KUBE_NAMESPACE}&from=${JOB_START_TIME_GRAFANA}&to=${JOB_END_TIME_GRAFANA}"

	# Prepare JSON with urls
    urls=$(cat <<EOF
{
    "kube_namespace": "${KUBE_NAMESPACE}",
    "project_id": "${CI_PROJECT_ID}",
    "mr_id": "${CI_MERGE_REQUEST_IID}",
    "deployment_type": "${CI_ENVIRONMENT_TIER}",
    "cluster": "${CLUSTER_DOMAIN}",
    "timestamp": "${CI_JOB_STARTED_AT}",
    "namespace_ds": "${NAMESPACE_DS}",
	"deviceserver_ds": "${DEVICESERVER_DS}",
    "database_ds": "${DATABASE_DS}",
    "job_logs": "${JOB_LOGS}",
    "testpod_logs": "${TESTPOD_LOGS}",
    "namespace_logs": "${NAMESPACE_LOGS}",
    "deviceconf_logs": "${DEVICECONF_LOGS}",
    "deviceserver_logs": "${DEVICESERVER_LOGS}",
    "databaseds_logs": "${DATABASEDS_LOGS}",
    "namespace_metrics": "${NAMESPACE_METRICS}",
    "deviceserver_metrics": "${DEVICESERVER_METRICS}",
    "workload_metrics": "${WORKLOAD_METRICS}",
    "pod_metrics": "${POD_METRICS}"
}
EOF
	)
	echo $urls
}

function getDashboardLinksForNamespace() {
	NAMESPACE_LINKS=$(getNamespaceLinks)
	RED="\e[31m"
	YELLOW="\e[33m"
	YELLOW_BG="\e[43m"
	BLUE="\e[34m"
	MAGENTA="\e[35m"
	GREEN_BG="\e[42m"
	CYAN_BG="\e[46m"
	NORMAL="\e[0m"
	BOLD="\e[1m"
	UNDERLINE="\e[4m"
	NEWLINE="\t\n"

	echo "--------------------------------------------------------------------------------------------"
	if [ "$CLUSTER_DATACENTRE" != "" ]; then
		echo -e "${BOLD}${YELLOW_BG}CLUSTER:${NORMAL} ${CLUSTER_DATACENTRE}-${CLUSTER_ENVIRONMENT}"
		echo -e "${NEWLINE}"
	fi
	echo -e "${BOLD}${CYAN_BG}DASHBOARD AND LOGS LINKS FOR NAMESPACE:${NORMAL} ${KUBE_NAMESPACE}"
	echo -e "${NEWLINE}"
	echo -e "${BOLD}${GREEN_BG}** HEADLAMP DASHBOARDS **${NORMAL}"
	echo -e "${BOLD}${MAGENTA}Namespace:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .namespace_ds)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}DeviceServer:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .deviceserver_ds)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}DatabaseDS:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .database_ds)${NORMAL}\n"
	echo -e "${NEWLINE}"
	echo -e "${BOLD}${RED}***** NOTE: Due to terminal limitations, you need to COPY AND PASTE the following URLs manually into your browser *****${NORMAL}"
	echo -e "${NEWLINE}"	
	echo -e "${BOLD}${GREEN_BG}** KIBANA LOGS **${NORMAL}"
	echo -e "${BOLD}${MAGENTA}Job Logs:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .job_logs)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}Test Pod Logs:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .testpod_logs)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}Namespace Logs:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .namespace_logs)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}Device Configuration Logs/SKA Tango Operator Logs:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .deviceconf_logs)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}DeviceServer Logs:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .deviceserver_logs)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}DatabaseDS Logs:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .databaseds_logs)${NORMAL}\n"
	echo -e "${NEWLINE}"
	echo -e "${BOLD}${GREEN_BG}** GRAFANA METRICS **${NORMAL}"
	echo -e "${BOLD}${MAGENTA}Namespace:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .namespace_metrics)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}Device Servers:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .deviceserver_metrics)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}Compute Resources by Workload:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .workload_metrics)${NORMAL}\n"
	echo -e "${BOLD}${MAGENTA}Compute Resources by Pod:${NORMAL}"
	echo -e "${BLUE}${UNDERLINE}$(echo $NAMESPACE_LINKS | jq -r .pod_metrics)${NORMAL}"
	echo -e "${NEWLINE}"
	echo "--------------------------------------------------------------------------------------------"
}

function createNamespace() {
	if [ "$CI" != "true" ]; then
		kubectl get namespace ${KUBE_NAMESPACE} > /dev/null 2>&1
		if [ $? -eq 0 ]; then
			kubectl describe namespace ${KUBE_NAMESPACE}
			return
		fi

		kubectl create namespace ${KUBE_NAMESPACE}
		return
	fi

	echo "createNamespace: Creating labeled namespace ..."
	export CICD_DOMAIN="cicd.skao.int"
	export MERGE_REQUEST_ASSIGNEES=""

	SCRIPT_DIR=$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &> /dev/null && pwd)

	if [ ! -z "$CI_MERGE_REQUEST_ID" ]; then
		export MERGE_REQUEST_ASSIGNEES="$(echo ${CI_MERGE_REQUEST_ASSIGNEES} | sed -E 's/,? and /,/g; s/ //g')"
	fi

	cat ${SCRIPT_DIR}/resources/namespace.yml | envsubst | kubectl apply 2>/dev/null -f -
}

function sendDashboardLinksForNamespace() {
	NAMESPACE_LINKS=$(getNamespaceLinks)
	echo "Sending links to Marvin..."
    curl -X POST "${AUTOMATION_LINKS_ENDPOINT_URL}" \
         -H "Content-Type: application/json" \
		 --max-time ${AUTOMATION_LINKS_POST_TIMEOUT_SECS} \
         -d "$NAMESPACE_LINKS" \
		 > /dev/null 2>&1 || true
}